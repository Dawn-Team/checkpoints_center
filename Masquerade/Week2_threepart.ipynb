{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Two 吴恩达《神经网络和深度学习》笔记\n",
    "## 2.7Computation Graph计算图\n",
    "1.一个计算流程图就是正向从左到右的计算，然后反向从右到左计算导数  \n",
    "\n",
    "\n",
    "## 2.8Derivatives with a Computation Graph计算图的导数计算\n",
    "1.对于$f(a)=3a$，右移a一个不可度量的值、一个无限小的值,f(a)会增加一个非常小的值的3倍，而这个函数任何地方的斜率总是等于3  \n",
    "\n",
    "\n",
    "## 2.9More derivatives examples更多导数的例子\n",
    "1.Python中:$\\frac{dJ}{dvar}$ \n",
    "\n",
    "## 2.10Logistic Regression Gradient descent logistic回归中的梯度下降法\n",
    "1.用导数流程图来计算logistic回归的梯度下降  \n",
    "$z=w^{T}x +b$  \n",
    "$\\hat{y} =a=sigmoid(z) $  \n",
    "$L(\\hat{y},y)=-(ylog(a)+(1-y)log(1-a))$  \n",
    "$da=-\\frac{y}{a}+\\frac{1-y}{1-a}$, $dz=a-y$, $dw1=x1dz$, $dw2=x2dz$, $db=dz$  \n",
    "repeat{$w_1:=w_1-\\alpha dw_1$,$w_2:=w_2-\\alpha dw_2$,$b:=b-\\alpha db$}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
