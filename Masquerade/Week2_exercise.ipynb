{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Two 吴恩达《神经网络和深度学习》练习\n",
    "## Python Basics with Numpy\n",
    "Task 1: sigmoid函数，np.exp()   \n",
    "- $sigmoid(x) = \\frac{1}{1+e^{-x}}$ 有时也称为逻辑函数。 它是一种非线性函数，不仅用于机器学习（Logistic回归），还用于深度学习。   \n",
    "\n",
    "code:  \n",
    "s = 1/(np.exp(-x)+1)  \n",
    "\n",
    "- x可以是实数，矢量或矩阵。我们在numpy中用来表示这些形状（向量，矩阵......）的数据结构称为numpy数组。  \n",
    "\n",
    "code:  \n",
    "s = 1/(np.exp(-x)+1)  \n",
    "\n",
    "Task 2: Sigmoid梯度  \n",
    "- $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))$$  \n",
    "- $$\\sigma'(x) = s(1-s)$$\n",
    "\n",
    "code:  \n",
    "s = 1/(np.exp(-x)+1)  \n",
    "ds = s*(1-s)  \n",
    "\n",
    "Task 3: np.shape,np.reshape()  \n",
    "- X.shape用于获得矩阵/向量X的形状（维度）。\n",
    "- X.reshape(...)用于将X重塑为其他维度。  \n",
    "\n",
    "code:  \n",
    "v = image.reshape(image.shape[0]* image.shape[1]* 2, 1)    \n",
    "\n",
    "Task 4: 归一化 changing x to $ \\frac{x}{\\| x\\|} $   \n",
    "code:  \n",
    "x_norm =np.linalg.norm(x,ord=2,axis=1,keepdims=True)  \n",
    "x=x*x/(x_norm*x_norm)  \n",
    "\n",
    "Task 5: 广播  \n",
    "code:  \n",
    "x_exp =np.exp(x)  \n",
    "x_sum =np.sum(x_exp,axis=1)  \n",
    "s = x_exp/x_sum.reshape(2,1)  \n",
    "\n",
    "Task 6: \n",
    "- $$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^m|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}$$  \n",
    "\n",
    "code:  \n",
    "loss = np.sum(abs(y-yhat))  \n",
    "\n",
    "- $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}$$  \n",
    "\n",
    "code:  \n",
    "loss = np.sum(abs(y-yhat)*abs(y-yhat))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with a Neural Network mindset  \n",
    "- numpy是使用Python进行科学计算的基础包。\n",
    "- h5py是与存储在H5文件中的数据集进行交互的常用包。\n",
    "- matplotlib是一个用Python绘制图形的库。\n",
    "- 这里使用PIL和scipy来测试您的模型，最后使用您自己的图片。  \n",
    "\n",
    "Task 1: train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3)  \n",
    "code:  \n",
    "m_train = train_set_x_orig.shape[0]  \n",
    "m_test = test_set_x_orig.shape[0]  \n",
    "num_px = train_set_x_orig.shape[1]  \n",
    "\n",
    "Task 2: X_flatten = X.reshape(X.shape[0], -1).T  \n",
    "code:  \n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T  \n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T  \n",
    "\n",
    "Task 3: np.exp()  \n",
    "code:  \n",
    "s = 1.0/(1+np.exp(-z))  \n",
    "\n",
    "Task 4: np.zeros()  \n",
    "code:  \n",
    "w = np.zeros((dim,1))  \n",
    "b = 0  \n",
    "\n",
    "Task 5: propagate()  \n",
    "- $$A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$$   \n",
    "- $$J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$$  \n",
    "- $$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})$$  \n",
    "\n",
    "code:  \n",
    "A = sigmoid(np.dot(w.T,X)+b)  \n",
    "cost = -(1/m)*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))  \n",
    "dw = 1/m*np.dot(X,(A-Y).T)  \n",
    "db = 1/m*np.sum(A-Y)  \n",
    "\n",
    "Task 6: $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$is the learning rate.  \n",
    "code:  \n",
    "grads, cost = propagate(w, b, X, Y)  \n",
    "w = w - learning_rate*dw  \n",
    "b = b - learning_rate*db    \n",
    "\n",
    "Task 7: $\\hat{Y} = A = \\sigma(w^T X + b)$  \n",
    "code:  \n",
    "A =sigmoid(np.dot(w.T,X)+b)  \n",
    "if A[0,i]<=0.5:  \n",
    "   Y_prediction[0,i] = 0  \n",
    "else:  \n",
    "   Y_prediction[0,i] = 1  \n",
    "\n",
    "Task 8:  \n",
    "code:    \n",
    "w, b = initialize_with_zeros(X_train.shape[0])  \n",
    "parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)  \n",
    "Y_prediction_test = predict(w, b, X_test)  \n",
    "Y_prediction_train = predict(w, b, X_train)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
