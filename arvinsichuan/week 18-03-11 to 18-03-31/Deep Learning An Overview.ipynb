{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning An Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Metworks and Deep Learning\n",
    "\n",
    "### Commonly Seen Networks\n",
    "1. Standard Nueral Network\n",
    "2. CNN\n",
    "3. RNN\n",
    "4. Custome Hybtid\n",
    "\n",
    "### Logistic Regression  \n",
    "Given $x$, want  $\\hat{y} = P(y=1 \\mid x)$, $x \\in \\Re^{n_x}$  \n",
    "Parameters: $w \\in \\Re^(n_x), b \\in \\Re$  \n",
    "Output: $\\hat{y} = \\sigma (w^Tx+b)$\n",
    "$\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "Loss(Error) Function    \n",
    "$L(\\hat{y}, y) = -[ylog\\hat{y}+(1-y)log(1-\\hat{y})]$\n",
    "Cost Function  \n",
    "$J(w,b) = \\frac{1}{m} \\sum_1^m L(\\hat{y}^{(i)},y) = \\frac{1}{m}\\sum_{1}^{m}[y^{(i)}log\\hat{y}^{(i)}+(1-y^{(i)})log(1-\\hat{y}^{(i)})]$\n",
    "\n",
    "### GD(Gradient Descent)  \n",
    "Repeadly{  \n",
    "    $w:=w - \\alpha\\frac{dJ(w)}{dw}$ \n",
    "}\n",
    "\n",
    "### Normalizing  \n",
    "$x_normalized =  \\frac{x}{\\left \\| x \\right \\|}$  \n",
    "\n",
    "\n",
    "### Softmax  \n",
    "for $x \\in \\Re^{'(xn)}, softmax(x) = softmax([x_1,... ,x_n])$\n",
    "$= [\\frac{e^{x_1}}{\\sum_{j}e^{x_j}},... ,\\frac{e^{x_n}}{\\sum_{j}e^{x_j}}]$ \n",
    "\n",
    "### Useful `np` Functions  \n",
    "```python\n",
    "# All are vectorization supported\n",
    "# e^x\n",
    "np.exp(x) \n",
    "\n",
    "# ||x||\n",
    "np.linalg.norm(x,axis=1,keepdim=True)\n",
    "\n",
    "# sum\n",
    "np.sum(x,axis=1,keepdim=True)\n",
    "\n",
    "# dot product\n",
    "np.dot(x,y)\n",
    "\n",
    "# outer product\n",
    "np.outer(x,y)\n",
    "\n",
    "# mathematical numerical multiply\n",
    "np.multiply(x,y)\n",
    "\n",
    "# reshape\n",
    "np.reshape(row,col)\n",
    "```\n",
    "\n",
    "### Common Steps for pre-processing a new dataset are:  \n",
    "1. Figure out the dimensions and the shapes of the problem(m_trian, m_test, num_px,...)\n",
    "2. Reshape the datasets such that each example is now a vector of size(num_px\\*num_px\\*3,1)\n",
    "3. Standardize the data.(Images can be applied by being devided by 255, which is the length of the color area)\n",
    "\n",
    "### To Implement a NN:  \n",
    "1. Initialize(w,b)\n",
    "2. Optimize the loss iteratively to learn parameters such as (w,b)   \n",
    "    - computing the cost and its gradient  \n",
    "    - updating the parameters using gtradient descent  \n",
    "3. Use the leart (w,b) to predict the labels for a given set of examples\n",
    "\n",
    "### For Better Algorithm effeciency and accuracy  \n",
    "1. Preprocessing the dataset is important\n",
    "2. Implement each function seperatedly and build a model together\n",
    "3. Tuning the learning rate (a kind of 'hyper-parameter') can make big difference to the algorithm\n",
    "\n",
    "### Shallow Neural Network  \n",
    "Repeatedly{\n",
    "$Z^{[i]} = W^{[i]}+b{[i]},$\n",
    "$A^{[i]} = \\sigma(Z^{[i]}ï¼‰$\n",
    "}\n",
    "\n",
    "### Activation Functions\n",
    "1. sigmoid:  \n",
    "$$\n",
    "a(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "2. tanh:  \n",
    "$$\n",
    "a(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n",
    "$$\n",
    "3. ReLU(Rectified Linear Unit):  \n",
    "$$\n",
    "    a(x) =max(0,x)\n",
    "$$\n",
    "4. Leaky ReLU:  \n",
    "$$\n",
    "a(x) = max(0.01*x,x)\n",
    "$$\n",
    "\n",
    "### Why do we need non-linear activation function?  \n",
    "If we use linear activation function, we just get a result of linear computation.\n",
    "\n",
    "### Derivatives of activation functions\n",
    "1. sigmoid:  \n",
    "$$\n",
    "g'(z)=g(z)[1-g(z)]\n",
    "$$\n",
    "2. ranh:\n",
    "$$\n",
    "g'(z)=1-[tan(z)]^2\n",
    "$$\n",
    "3. Relu:  \n",
    "$$\n",
    "g(z) = \n",
    "\\left\\{\\begin{matrix}\n",
    "0 & ,if\\ z < 0 \\\\ \n",
    "1 & ,if\\ z >0 \\\\\n",
    "undefined & ,if z=0 \n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "4. Leaky ReLU:\n",
    "$$\n",
    "g(z) = \n",
    "\\left\\{\\begin{matrix}\n",
    "0.01 & ,if\\ z < 0 \\\\ \n",
    "1 & ,if\\ z >0 \\\\\n",
    "undefined & ,if z=0 \n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "### General GD Algorithm\n",
    "1. Forward Propagation:\n",
    "$$\n",
    "Z^{[i]} = W^{[i]}X^{[i-1]} + b^{[i]},\\\\  \n",
    "A^{[i]} = g^{[i]}(Z^{[i]})\n",
    "$$\n",
    "2. Backward Propagation:  \n",
    "$$\n",
    "d_Z^{[i]} = W^{[i+1]T}d_z^{[i+1]} * g'^{[i]}(Z^{[i]})\\\\  \n",
    "d_w^{[i]} = \\frac{1}{m}d_z^{[i]}X^T\\\\ \n",
    "d_b^{[i]} = \\frac{1}{m}\\sum d_z^{[i]}\n",
    "$$\n",
    "3. Update Weights:\n",
    "$$\n",
    "W = W - \\alpha * d_W\\\\\n",
    "b = b - \\alpha * d_b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Deep NN - Hyper-parameters tuning, Regularization and Optimization  \n",
    "\n",
    "### Setting Up Machine Learning Applications\n",
    "#### Hyper-parameters\n",
    "1. \\# layers\n",
    "2. \\# hidden layers\n",
    "3. learning rate\n",
    "4. activation functions\n",
    "\n",
    "| Condition   |Train Sets     | Dev Sets (Cross Validation)    | Test Sets(Optional)    |\n",
    "| :------------- | :------------- | :------------- |:------------- |\n",
    "| small amount of data     | 60      | 20    | 20    |\n",
    "| big data    | 98    | 1    | 1    |\n",
    "\n",
    "#### Make sure Dev and Test the same distribution.\n",
    "Test ensures how performance will be on the target so it is necessary to keep them the same distribution.\n",
    "\n",
    "#### Bias And Variance\n",
    "- Bias measures how the performance is between train set accuracy and the baseline(generally, will be human level performance).\n",
    "- Variance measures how the performance of Dev set compared with the Train set.\n",
    "\n",
    "#### Solution for high Bias and Variance\n",
    "1. High Bias:\n",
    "    - Bigger Network\n",
    "    - Train Longer\n",
    "    - NN architecture research\n",
    "2. High Variance:\n",
    "    - More Data\n",
    "    - Regularization\n",
    "    - NN architecture research\n",
    "\n",
    "### Regularization\n",
    "- $L_1$ Regularization:\n",
    "$$\n",
    "\\left \\| w \\right \\|^{2}_{2} = \\sum_{j = 1}^{n_x} w_j^2 = w^Tw\n",
    "$$\n",
    "\n",
    "- $L_2$ Regularization: \n",
    "$$\n",
    "\\frac{\\lambda}{2m}\\sum_{j = 1}^{n_x}|w_j|=\\frac{\\lambda}{2m}\\left \\| w \\right \\|_1\n",
    "$$\n",
    "- Frobenius Norm\n",
    "$$\n",
    "\\left \\| w^{[L]} \\right \\|^2_F = \\sum_{i = 1}^{n^{[L-1]}}|w_j|\\sum_{j = 1}^{n^{[L-1]}}(w_{ij})^2\n",
    "$$\n",
    "\n",
    "#### How does regularization prevent overfitting?\n",
    "Some of the hidden layer has been waken so that the overfitting has been modified, too.  \n",
    "Because of the regularization parameter to reduce the weights to more close to zero, so the real function is more close to a linear function.\n",
    "\n",
    "### Dropout Regularization\n",
    "#### What's a dropout?\n",
    "- Eliminating some hidden unit randomly\n",
    "- No dropout when making prediction \n",
    "\n",
    "#### Why does dropout works?\n",
    "- Overfitting is happening so we can't rely on any one feature, and thus we choose to spread out weights.  \n",
    "- To different Layer, choose relatively drop-out `keep_prov` value(usually not for input layer).\n",
    "- No overfitting, no dropout.\n",
    "\n",
    "### Other way to regularization\n",
    "- Data Augmentation\n",
    "    - flipping horizontally\n",
    "    - randomly distortion/zooming\n",
    "- Early Stopping\n",
    "\n",
    "### Orthogonalization \n",
    "1. Optimize cost function:\n",
    "    - Gradient descent\n",
    "    - Momentum\n",
    "    - RMS Prop\n",
    "    - Atom\n",
    "2. Non-overfit\n",
    "    - Regularization\n",
    "    - Getting more data\n",
    "3. Early stop can't make you handle two of above problem independently.\n",
    "\n",
    "4. Bias $\\to $ error rate & Variance $\\to$ overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your optimization problem \n",
    " \n",
    "### Normalizing training sets\n",
    "Normalizing training set can make the train process have a equal  probability at any direction so that it can improve train efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients Vanishing/Exploding\n",
    "\n",
    "When the number of layers becomes very large that stacked together weights from them can be magnified or reduced to a very large/small value (that a computer memory unit can not hold), this situation is called the Gradient Exploding/Vanishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Initialization \n",
    "- A [reference](https://zhuanlan.zhihu.com/p/25110150)\n",
    "- Zero Initialization, output will always be same, equivalent to linear regression.\n",
    "- Random Initialization, hard to train\n",
    "- Xavier Initialization: $random*\\sqrt\\frac{1}{layer^{l-1}}$\n",
    "- He Initialization: $random*\\sqrt\\frac{2}{dim^{previous\\_layer}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Checking can be an efficient way to debug a neural network\n",
    "\n",
    "Often we use **Approximation of gradients** to check the gradients.\n",
    "\n",
    "#### Gradient Checking Notes\n",
    "1. Don't use in training, ONLY for debug\n",
    "2. If algorithm fails grad check, look at components to try to identify bug.\n",
    "3. Remember Regularization when calculate the grad\n",
    "4. Doesn't work with dropout.(set dropout parameter `keep_prob` to `1`)\n",
    "5. Run at random initialization; perhaps again after some training.\n",
    "\n",
    "### Practice Instructions\n",
    "#### Initialization\n",
    "##### zero initialization\n",
    "- the weight $W^{[l]}$ should be initialized randomly to break symmetry.\n",
    "- It is okay to initialize $b^{[l]}$ to zeros, symmetry is still broken so long as $W^{[l]}$  is initialized randomly.\n",
    "\n",
    "##### Random Initialization \n",
    "Problem may happen: infinite after 0 iteration.\n",
    "- initializing weights to very large random values doesn't work well.\n",
    "Problem may happen: infinite cost.\n",
    "- Initializing weights to smaller values\n",
    "\n",
    "##### Xavier Initialization\n",
    "$$\n",
    "random\\_number*\\sqrt\\frac{1}{layer^{[l-1]}}\n",
    "$$\n",
    "\n",
    "##### He Initialization \n",
    "$$\n",
    "random\\_number*\\sqrt\\frac{2}{dimension\\_of\\_previous_layer}\n",
    "$$\n",
    "\n",
    "##### Tips\n",
    "1. Different initialization lead to different results\n",
    "2. Random initialization is used to break symmetry and make sure different hidden units can learn different things.\n",
    "3. Don't initialize to values that are two large.\n",
    "4. He Initialization works well form networks with ReLU activations\n",
    "\n",
    "#### Regularization\n",
    "##### $L_2$ Regularization\n",
    "Depend on the assumption that a model with smell weights than the larger ones.  \n",
    "\n",
    "Implementation of $L_2$ Regularization is on: \n",
    "- The cost function: \n",
    "    - A regularization term is added to the cost-entropy cost\n",
    "- The back-propagation function: \n",
    "    - There are extra terms in the gradients with respect to weights matrix\n",
    "- Weights end up smaller(\"Weights decay\" situation) \n",
    "    - weights are pushed to smaller ones.\n",
    "\n",
    "##### Dropout\n",
    "- A regularization technique\n",
    "- Only use dropout in training, never in training.\n",
    "- Apply dropout both in forward and backward\n",
    "- Scale the value using dividing `keep_prob` due to the shutting off of the neurons(keep result the same level of numeric).\n",
    "\n",
    "#### Tips\n",
    "- Regularization will help reduce overfitting problem\n",
    "- Regularization will drive weights to lower values.\n",
    "- $L_2$ Regularization and Dropout are two very effective regularization techniques.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "S_{db}^{corrected}+\\epsilon": "<p><strong>SyntaxError</strong>: invalid syntax (<ipython-input-1-ef264ba77cc8>, line 1)</p>\n",
     "S_{dw}^{corrected}+\\epsilon": "<p><strong>SyntaxError</strong>: invalid syntax (<ipython-input-1-54c0e7b0129e>, line 1)</p>\n"
    }
   },
   "source": [
    "## Optimization Algorithms\n",
    "### MIni-Batch vs Batch Training\n",
    "Problem to address: the data is so giant that really cost time and computation resources.\n",
    "\n",
    "mini-batch method will update weights in a batch-split way, and the weights will be apparently not updated continuously.\n",
    "The size of batch should not be 1(No vectorization,train one example each time) or m(the batch training, losing efficiency) but some value between them.\n",
    "#### Methodology\n",
    "- If training set is small(typically less than thousand), choose batch training.\n",
    "- If the size of training set is large, the exponentials of 2 are recommended as the batch size to fit the Computer Memory units size.\n",
    "\n",
    "### Exponentially weighted averages.\n",
    "(Also known as exponentially weighted moving averages)\n",
    "The current value(weights) depends on the several previous ones(controlled by the parameter $\\beta$). This technique will be used for speed up closing to the convergence point.\n",
    "$$\n",
    "V_t = \\beta V_{t-1} + (1-\\beta)Q_t\n",
    "$$\n",
    "**Bias Correction**\n",
    "The value may be very small so the following value by this method may be at a very large bias.\n",
    "To eliminate this, we can use this to remove the bias:\n",
    "$$\n",
    "\\frac{V_t}{1-\\beta^t}\n",
    "$$\n",
    "\n",
    "\n",
    "### Optimization Algorithms\n",
    "#### Momentum\n",
    "##### On iteration t:\n",
    "Compute dw,db on the current mini-batch and\n",
    "$$\n",
    "V_{dw} = \\beta V_{dw} + (1-\\beta)dw \\\\\n",
    "V_{db} = \\beta V_{db} + (1-\\beta)db \\\\\n",
    "W = W - \\alpha V_{dw}, b = b - \\alpha V_{db}\n",
    "$$\n",
    "\n",
    "##### Hyper-parameters\n",
    "$\\alpha, \\beta(0.9\\ by\\ convention)$\n",
    "\n",
    "#### RMSprop\n",
    "##### On iteration t:\n",
    "Compute dw,db on the current mini-batch and\n",
    "$$\n",
    "S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dw^2 \\\\\n",
    "S_{db} = \\beta_2 V_{db} + (1-\\beta_2)db^2 \\\\\n",
    "W = W - \\alpha \\frac{dw}{\\sqrt{S_{dw}+\\epsilon}}, b = b - \\alpha \\frac{db}{\\sqrt{S_{db}+\\epsilon}}\n",
    "$$\n",
    "$\\epsilon$ is for the zero case of the `dw` and `db`.\n",
    "\n",
    "##### Hyper-parameters\n",
    "$\\alpha, \\beta_2, \\epsilon$\n",
    "\n",
    "#### Adam Optimization\n",
    "##### On iteration t:\n",
    "Firstly, $V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0$  \n",
    "Compute dw,db on the current mini-batch and\n",
    "1. The momentum part:  \n",
    "$$\n",
    "V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dw \\\\\n",
    "V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db \\\\\n",
    "$$\n",
    "2. The RMS prop part:\n",
    "$$\n",
    "S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dw^2 \\\\\n",
    "S_{db} = \\beta_2 V_{db} + (1-\\beta_2)db^2 \\\\\n",
    "$$\n",
    "\n",
    "3. Bias Correction:\n",
    "$$\n",
    "V_{dw}^{corrected} = \\frac{V_{dw}}{1-\\beta_1^t}, V_{db}^{corrected} = \\frac{V_{db}}{1-\\beta_1^t} \\\\\n",
    "S_{dw}^{corrected} = \\frac{S_{dw}}, S_{db}^{corrected} = \\frac{S_{db}}{1-\\beta_2^t}\n",
    "$$\n",
    "\n",
    "4. Update the parameters:\n",
    "$$\n",
    "W = W - \\alpha \\frac{V_{dw}^{corrected}}{\\sqrt{{S_{dw}^{corrected}+\\epsilon}}}, \\\\\n",
    "b = b - \\alpha \\frac{V_{db}^{corrected}}{\\sqrt{{S_{db}^{corrected}+\\epsilon}}}\n",
    "$$\n",
    "\n",
    "##### Hyper-parameters\n",
    "| Parameter Name    | Suggest Value     | Meaning    |  \n",
    "| :---------| :--------| :--------|\n",
    "| $\\alpha$    | needs to be tuned    | learning rate    |\n",
    "| $\\beta_1$    | 0.9    | $dw$ for computing exponentially average    | \n",
    "| $\\beta_2$    | 0.999    | $dw^2$ for computing exponentially average     |  \n",
    "| $\\epsilon$    | $10^{-8}$    | Eliminating the illegal division by zero    |\n",
    "\n",
    "\n",
    "#### Learning Rate Decay\n",
    "Problem to address: learning rate to be smaller when the training is on thousands of iteration.\n",
    "- One way\n",
    "$$\n",
    "\\alpha = \\frac{1}{1 + decay\\_rate * epoch\\_num}\\alpha_0\n",
    "$$\n",
    "$\\alpha_0$ and the decay rate are another kind of hyper-parameter.\n",
    "\n",
    "-Other ways:  \n",
    "Exponential Decay\n",
    "$$\n",
    "\\alpha = 0.95 * \\alpha_0\n",
    "$$\n",
    "the `0.95` is an example but it should be some number less than one slightly.\n",
    "$$\n",
    "\\alpha = \\frac{k}{\\sqrt{epoch\\_num}}*\\alpha_0, \\\\\n",
    "or\\\\\n",
    "\\alpha = \\frac{k}{\\sqrt{t}}*\\alpha_0\n",
    "$$\n",
    "\n",
    "#### Practice Instructions\n",
    "##### Mini-Batch(for the samples):\n",
    "- Shuffling and Partition are two steps required to build mini-batches\n",
    "- Powers of two are often chosen to be the mini-batch size, lie 2,4,8,...\n",
    "\n",
    "##### Momentum\n",
    " - The Velocity is initialized with zeros so it will take a few iterations to build up and start to bigger steps.\n",
    " - If $\\beta=0$, the momentum is disabled\n",
    " - choosing of $\\beta$: \n",
    "     - Larger value of $\\beta$, the steps are going smoother.\n",
    "     common value range from 0.8 to 0.999, 0.9 is usually used for default.\n",
    " - Tips:\n",
    "     - Momentum takes past gradients into account to smooth out the steps of GD.\n",
    "     - It can be applied with batch gradient descent, mini-batch GD or stochastic GD(SGD).\n",
    "     - You have to tune a momentum parameter $\\beta$ and a learning rate $\\alpha$\n",
    "\n",
    "\n",
    "#### Adam\n",
    "The Advantages of Adam; \n",
    "- Relatively low memory requirements\n",
    "- Usually works well even with little tuning of hyper-parameters(except for $\\alpha$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning\n",
    "\n",
    "### Tuning Priority.\n",
    "P=Priority:  \n",
    "P1. Tuning $\\alpha$.  \n",
    "P2.1. Tuning $\\beta$.  \n",
    "Default Order: $\\beta_1$ $\\beta_2$ $\\epsilon$  \n",
    "P2.2. Mini-batch size.\n",
    "P2.3. Number of hidden units.\n",
    "P3.1. Number of layers.\n",
    "P3.2. Learning rate decay. \n",
    "\n",
    "Try random values rather than a grid. We use random search because we want search more in the possible important hyper-parameter results space.\n",
    "\n",
    "Summary: use random sampling not grid searching and optionally consider implementing a coarse to fine sampling schema.\n",
    "\n",
    "### Using an appropriate scale to pick hyper-parameter.\n",
    "\n",
    "$\\alpha \\in [0.0001,1]$, but not search within the range of this. Instead, use a candidate value for $\\alpha$ like 0.0001,0.001,0.01,0.1,...or \n",
    "$$\n",
    "r = -4 * random \\\\\n",
    "\\alpha = 10^{r}\n",
    "$$\n",
    "\n",
    "### Hyper-parameter for exponentially weighted averages.\n",
    "Cause the value for $\\beta$ measures the importance range, like $\\beta = 0.9$ can conclude a result from last 10 values.  \n",
    "Suggestion for the $\\beta$ value is: $\\beta \\in [0.001,0.1]$. Implementation example:  \n",
    "```python\n",
    "r = np.random.randn(-3,-1)\n",
    "beta = 1 - 10**(r)\n",
    "```\n",
    "Why not use linear way to search the possible value?  \n",
    "When the parameters go to some value, the value becomes more sensitive so that the search should be concentrate on those areas.\n",
    "\n",
    "\n",
    "### Hyper-parameter tuning in practice: Panda way vs. Caviar  \n",
    "If having large scale of computation resources, use a parallel way to search the possible hyper-parameters. This is the way we called Caviar way. However if the resources is not so enough, we just babysitting one model once. This is called the Panda way.\n",
    "\n",
    "\n",
    "\n",
    "### Batch Normalization\n",
    "For hidden layer l, can we normalize the input of layer l to make learning faster?  \n",
    "$$\n",
    "\\mu = \\frac{1}{m}\\sum x^{(i)} \\\\\n",
    "x = x - \\mu \\\\\n",
    "\\sigma^2 = \\frac{1}{m}\\sum {(x^{i})}^2 \\\\\n",
    "x = \\frac{x}{\\sigma^2}\n",
    "$$ \n",
    "\n",
    "Implementation of batch normalization:   \n",
    "Given some intermediate value in neural network, like: $z^{(1)},...,z^{(i)}$  \n",
    "$$\n",
    "\\mu = \\frac{1}{m}\\sum z^{(i)} \\\\\n",
    "\\sigma^2 = \\frac{1}{m}\\sum (z_i - \\mu)^2 \\\\\n",
    "z_{norm}^{(i)} = \\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\epsilon}} \\\\\n",
    "\\tilde{z}^{(i)} = \\gamma z_{norm}^{i} + \\beta\n",
    "$$\n",
    "The parameter $\\gamma$ is a learnable parameter. And if $\\gamma = \\sqrt{\\sigma^2 + \\epsilon}$, the $\\tilde{z}^{(i)} = z^{(i)}$.\n",
    "\n",
    "Note that when implementing normalization, parameters in the normalization and regularization should also be updated.\n",
    "\n",
    "#### Why does the Batch Normalization work?\n",
    "What Batch Normalization does is it reduces the amount that the distribution of these hidden units values shifts around. NORMALIZE is just make is normal to use.\n",
    "##### Batch Normalization as regularization \n",
    "- Each mini-batch is scaled by the mean/variance computed on just that mini-batch\n",
    "- This adds some noise to the value $z^{[l]}$ within that mini-batch. So it's similar to dropout operation. it adds some noise to each hidden layer's activations by randomly shutting down some units.\n",
    "- This just has a SLIGHT regularization effects so do not turn it to a regularization choice.  \n",
    "PS: When the mini-batch size becomes larger, the regularization effect become more obvious.  \n",
    "\n",
    "### Multi-class classification  \n",
    "#### Softmax Regression\n",
    "let the C to be the number of classes.  \n",
    "The output probabilities added together should be 1.  \n",
    "Say layer l has; $Z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$  \n",
    "The Activation function is:\n",
    "$$\n",
    "t = e^{z^{[l]}}, \\\\\n",
    "a^{[l]}_i = \\frac{t_i}{\\sum_{j=0}^{C}t_j}\n",
    "$$\n",
    "\n",
    "### Deep Learning frameworks\n",
    "#### Famous Frameworks\n",
    "- Caffe/Caffe2\n",
    "- CNTK\n",
    "- DL4J\n",
    "- Keras\n",
    "- Lasague\n",
    "- mxnet\n",
    "- Paddlepaddle\n",
    "- Tensorflow\n",
    "- Theano\n",
    "- Torch\n",
    "\n",
    "#### When choosing a Deep Learning framework, Consider:\n",
    "- Ease of programming(development and deployment)\n",
    "- Running speed\n",
    "- Truely open(open source and good governance)\n",
    "\n",
    "\n",
    "#### When using Tensorflow, the common steps are:\n",
    "1. Define variables and placeholders\n",
    "2. Define a cost function.\n",
    "3. Define a train method.\n",
    "4. Initialize the variables\n",
    "5. Get the session and iterate.\n",
    "\n",
    "#### Practice Instructions\n",
    "- Create placeholders:\n",
    "```python\n",
    "x = tf.placeholder(tf.float32,name='')\n",
    "```\n",
    "\n",
    "- Specify the computation graph to operations you want to compute:\n",
    "```python\n",
    "Y = WX + b\n",
    "sig = tf.sigmoid()\n",
    "```\n",
    "\n",
    "- Create the session;\n",
    "```python\n",
    "with tf.session as session:\n",
    "    .....\n",
    "```\n",
    "\n",
    "- Run the session using a feed dictionary if necessary to specify placeholder variables names:\n",
    "```python\n",
    "session.run (sigmoid, feed_dict={...;...})\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Machine Learning Projects\n",
    "### Why ML Strategy?\n",
    "When already finish some work in a model, but it is not so accurate. So the question is where is the better place to start finding a solution to improve it?\n",
    "\n",
    "### Orthogonalization\n",
    "It should be a orthogonalized way to find ways.\n",
    "\n",
    "\n",
    "### Setting up goal\n",
    "#### Single number evaluation metric\n",
    "The evaluation metric should be single and single only.  \n",
    "\n",
    "- $F_1$ Score:\n",
    "$$\n",
    "F_1 = \\frac{2}{\\frac{1}{P}+\\frac{1}{R}}\n",
    "$$\n",
    "\n",
    "#### Train/Dev/Test Distributions\n",
    "- Test sets is the result of the final model, the confidence of your algorithm.\n",
    "- Dev and validation metric should be same with test so that there will we can highly efficiently innovate and optimize the algorithm.\n",
    "\n",
    "#### Size of Dev and Test sets\n",
    "Total size is larger, the train set is larger.\n",
    "It's okay not having a test set.\n",
    "\n",
    "#### We could add some extra bias weights to some special case, like porn problem\n",
    "\n",
    "### Human Level Performance.\n",
    "#### Why Human Level Performance?\n",
    "1. Machine Learning becomes efficient suddenly to compete with human-level performance.\n",
    "2. Work flow is much more efficient to allow Machine Learning project to do what human can also do.\n",
    "3. Human is good at lots of tasks so human-level performance is a approximate to Bayer Optimal error.\n",
    "\n",
    "To get a better performance to human-level performance(or some kind of Bayer Optimal level):\n",
    "- Get labeled data from human\n",
    "- Gain insight from manual error analysis like: Why did a person get this right(but the model under building is not)?\n",
    "- Better analysis of bias/variance.\n",
    "\n",
    "#### Avoidable bias and variance.\n",
    "Say we have example:    \n",
    "\n",
    "| Object    | Accuracy 1    | Accuracy 2    |  \n",
    "| :--------| :--------| :--------|  \n",
    "| Human    | 1    | 7.5    |\n",
    "| Train Error    | 8    | 8    |\n",
    "| Dev Error    | 10    | 10    |\n",
    "| Solution    | Focus on Bias    | Focus on variance     |\n",
    "\n",
    "In the example, the error between human level performance and the Train Error is \"Avoidable Bias\" and the error between Train error and the Dev Error is variance.\n",
    "\n",
    "#### Understanding human level performance\n",
    "##### Human level as a proxy for Bayer Error.\n",
    "In the following example, a medical image classification example, suppose:\n",
    "\n",
    "| Object    | Accuracy    |  \n",
    "| :--------| :--------|  \n",
    "| Typical Human    | 3%    |  \n",
    "| Typical Doctor    | 1%    |  \n",
    "| Experimental Doctor    | 0.7%    |  \n",
    "| Team of experimental Doctor    | 0.5%    |\n",
    "\n",
    "So what is a \"human-level performance\" ?\n",
    "the last column, a 0.5% error accuracy. (By Bayer Definition, the top level performance)\n",
    "\n",
    "When Choosing a model to next iteration or production or some thing. Choose the one that has closest accuracy to the human level performance.\n",
    "\n",
    "\n",
    "##### Surpassing Human Level Performance.\n",
    "When the performance of a model or system is higher than the human can achieve.\n",
    "Examples:  \n",
    "- Online advertising\n",
    "- Product Recommendation\n",
    "- Logistics\n",
    "- Loan Approvals\n",
    "- ...\n",
    "\n",
    "\n",
    "##### Improving your model performances.\n",
    "- To eliminate avoidable bias:\n",
    "    - Train bigger model\n",
    "    - Train longer/better optimization algorithms.(Momentum, RMS prop, Adam,...)\n",
    "    - Neural Network Architecture/Hyper-parameter search(RNN,CNN).\n",
    "- To eliminate variance:\n",
    "    - More data\n",
    "    - Regularization($L_2$, Dropout, data augmentation)\n",
    "    - Neural Network Architecture/Hyper-parameter search.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----  \n",
    "\n",
    "<a rel=\"license\" style=\"text-decoration:none\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">\n",
    "    <div style=\"margin-top:0.5em;margin-bottom:1em;\">\n",
    "        <img alt=\"Creative Comments\" style=\"display:inline;\"  src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg\"/>\n",
    "        <img alt=\"Attribution\" style=\"display:inline;margin-top:0;\"  src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg\"/>\n",
    "        <img alt=\"Non-Commercial\" style=\"display:inline;margin-top:0;\"  src=\"https://mirrors.creativecommons.org/presskit/icons/nc.svg\"/>\n",
    "        <img alt=\"Non-Commercial\" style=\"display:inline;margin-top:0;\"  src=\"https://mirrors.creativecommons.org/presskit/icons/nc-jp.svg\"/>\n",
    "        <img alt=\"Share Alike\" style=\"display:inline;margin-top:0;\"  src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg\"/>\n",
    "     </div>\n",
    "</a>\n",
    "<br />\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "CREATED BY [ArvinSiChuan](mailto:arvinsc@foxmail.com?subject=Deep%20Learning%20An%20Overview), 06-Apr-2018.  \n",
    "Updated at 06-Apr-2018, VERSION SNAPSHOT-1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
